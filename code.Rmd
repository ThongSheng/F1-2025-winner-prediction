---
title: "527 F1 Final Project"
author: "Joy Gao"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(corrplot)
library(tidymodels)
library(kknn)
library(randomForest)
```

# Import Dataset

```{r}
set.seed(123)

# Import dataset
dir <- "~/Documents/STAT 527/archive (3)/"
#dir <- "C:/Users/thong/Downloads/archive/"
files <- c("constructor_standings",
           "constructors",
           "drivers",
           "lap_times",
           "pit_stops",
           "qualifying",
           "races",
           "results")
for (f in files) {
  file_path <- file.path(paste0(dir, f, ".csv"))
  temp_df <- read.csv(file_path)
  assign(paste0(f,"_ori"), temp_df)
}

```

# Preprocessing
```{r}
# Selecting and filtering relevant information
races <- races_ori |> 
  filter(year >= 2020) |> 
  select(raceId, year, round)
constructor_standings <- constructor_standings_ori |> 
  select(raceId, constructorId, position) |> 
  rename(cs_position = position)
constructors <- constructors_ori |> 
  select(constructorId, constructorRef) |>
  rename(constructor = constructorRef)
drivers <- drivers_ori |> 
  select(driverId, code) |>
  rename(driver = code)
lap_times <- lap_times_ori |> 
  group_by(raceId, driverId) |>
  summarise(lap_time = mean(milliseconds), .groups = "drop") |> # we use mean lap time instead of sum to account for DNFs
  select(raceId, driverId, lap_time)
pit_stops <- pit_stops_ori |> 
  group_by(raceId, driverId) |>
  summarise(stop_time = mean(milliseconds), .groups = "drop") |>
  select(raceId, driverId, stop_time)
qualifying <- qualifying_ori |> 
  select(raceId, driverId, constructorId, position) |> 
  rename(qual_position = position)
results <- results_ori |> 
  select(raceId, driverId, constructorId, grid, positionOrder) |>
  rename(final_grid = grid, final_position = positionOrder)
```


```{r}
# Merge data
merged_df <- constructors |> 
  inner_join(results, by="constructorId") |> 
  inner_join(races, by="raceId") |>
  left_join(drivers, by = "driverId") |>
  left_join(lap_times, by = c("raceId", "driverId")) |>
  left_join(pit_stops, by = c("raceId", "driverId")) |>
  left_join(constructor_standings, by=c("constructorId", "raceId")) |>
  left_join(qualifying, by=c("constructorId", "driverId", "raceId"))
```


```{r}
# Calculate average of predictors (since each team has two drivers) and reorder columns
avg_df <- merged_df |> 
  group_by(constructorId, constructor, raceId, year, round) |> 
  summarise(avg_qual_position = mean(qual_position, na.rm=TRUE), 
            avg_final_grid = mean(final_grid, na.rm=TRUE),
            avg_final_position = mean(final_position, na.rm=TRUE),
            avg_lap_time = mean(lap_time, na.rm=TRUE),
            avg_stop_time = mean(stop_time, na.rm=TRUE),
            cs_position = first(cs_position), # cs_position is unique per constructor, just take the first one instead of averaging
            .groups = "drop") |>
  arrange(raceId, constructorId) |>
  select(raceId, year, round, constructorId, constructor, avg_qual_position, avg_lap_time, avg_stop_time, avg_final_grid, avg_final_position, cs_position)

# Final cleaning
df <- avg_df |> 
  drop_na() |> # drop all rows with NA (at this point any NA would mean double DNF, or Belgian 2021)
  group_by(constructorId) |> filter(n_distinct(year) >= 2) |> # remove teams with less than 2 years history
  ungroup()

```

# Data Exploration and Visualizations

### Line plots
```{r}
f1_colors <- c(
  "mercedes"      = "#00D2BE",
  "ferrari"       = "#DC0000",
  "red_bull"      = "#0600EF",
  "mclaren"       = "#FF8700",
  "alpine"        = "#0090FF",
  "aston_martin"  = "#006F62",
  "haas"          = "#787878",
  "alphatauri"    = "#2B4562",
  "alfa"          = "#900000",
  "williams"      = "#005AFF"
)

### Line plots

# Team's championship rankings over the years
df %>%
  group_by(year, constructor) %>%
  summarise(mean_cs = mean(cs_position, na.rm = TRUE), .groups = "drop") %>%
  ggplot(aes(x = year, y = mean_cs, color = constructor, group = constructor)) +
  geom_line(linewidth = 1.2) +
  geom_point(size = 2) +
  scale_y_reverse(breaks=1:10) +  # Lower ranks (1st place) at the top
  scale_color_manual(values = f1_colors) + 
  labs(x = "Year",
       y = "Championship Position",
       color = "Constructor") +
  theme_minimal(base_size = 14)

# Team's avg finishing position and qualifying performance over time 
plot_df <- df %>%
  group_by(year, constructor) %>%
  summarise(
    Qualifying = mean(avg_qual_position, na.rm = TRUE),
    Grand_Prix = mean(avg_final_position, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  pivot_longer(cols = c(Qualifying, Grand_Prix), names_to = "Metric", values_to = "Position")

ggplot(plot_df, aes(x = year, y = Position, color = constructor, group = constructor)) +
  geom_line(linewidth = 1) +
  geom_point(size = 2) +
  scale_y_reverse() +   
  scale_color_manual(values = f1_colors) +
  facet_wrap(~Metric) + 
  labs(
    x = "Year",
    y = "Average Position",
    color = "Constructor"
  ) +
  theme_minimal(base_size = 14)

```

### Other plots 
```{r}
# Bar plot of mean lap time by team
mean_lap_df <- df %>%
  group_by(constructor) %>%
  summarise(mean_lap_time = mean(avg_lap_time, na.rm = TRUE)) %>%
  arrange(mean_lap_time)  # fastest team first

ggplot(mean_lap_df, aes(x = reorder(constructor, mean_lap_time), y = mean_lap_time, fill=constructor)) +
  geom_col() +
  labs(
    x = "Constructor",
    y = "Mean Lap Time (ms)"
  ) +
  theme_minimal(base_size = 14) +
  theme(legend.position = "none") +
  coord_flip()

# Heatmap of team championship ranking by year
df_heat <- df %>%
  group_by(constructor, year) %>%
  summarise(mean_cs = mean(cs_position, na.rm = TRUE), .groups = "drop")

ggplot(df_heat, aes(x = factor(year), y = constructor, fill = mean_cs)) +
  geom_tile(color = "white") +
  scale_fill_viridis_c(direction = -1) +  # Darker = better rank
  labs(x = "Year",
       y = "Constructor",
       fill = "CS Position") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Scatterplot of lap time vs. qualifying time across teams
ggplot(df, aes(x = avg_qual_position, y = avg_lap_time, color = constructor)) +
  geom_point() +
  scale_color_manual(values = f1_colors) + 
  facet_wrap(~ constructor, scales = "free") +
  labs(x = "Average Qualifying Position",
       y = "Average Lap Time") +
  theme_minimal() +
  theme(legend.position = "none")

# Heatmap of correlation matrix
cor_data <- df %>%
  ungroup() %>%
  select(avg_qual_position, avg_lap_time, avg_stop_time, avg_final_grid, avg_final_position)

corrplot(cor(cor_data),
         method = "color",
         type = "upper",
         order = "hclust",
         addCoef.col = "black",
         tl.col = "black",
         tl.srt = 45,
         mar = c(0,0,2,0))
```

# Modeling and Evaluation

### KNN
```{r}
# Train-test split
split <- initial_split(df, prop = 0.8, strata = cs_position)
train_data <- training(split)
test_data  <- testing(split)


##### KNN code 

# recipe
f1_rec <- recipe(cs_position ~ ., data = train_data) |>
  update_role(raceId, year, round, constructorId, constructor, new_role = "ID") |>
  step_impute_median(all_numeric_predictors()) |>
  step_normalize(all_numeric_predictors())

# KNN model (regression) - treating cs_position as numeric here since it's ranked (we then compare with the ordinal regression model)
knn_model <- nearest_neighbor(
  neighbors = tune()
) |>
  set_engine("kknn") |>
  set_mode("regression")

# fit
knn_wf <- workflow() |>
  add_recipe(f1_rec) |>
  add_model(knn_model)

# validate KNN with Cross-Validation
cv_folds <- vfold_cv(train_data, v = 5)

knn_res <- tune_grid(
  knn_wf,
  resamples = cv_folds,
  grid = tibble(neighbors = seq(3, 25, by = 2)),
  metrics = metric_set(rmse, mae, rsq)
)

collect_metrics(knn_res)

### Final model with best k
best_k <- select_best(knn_res, metric="rmse")
best_k

final_knn <- finalize_workflow(knn_wf, best_k) |>
  fit(train_data)

# Evaluate on test dataset
knn_preds <- predict(final_knn, test_data) |>
  bind_cols(test_data)

# Print metrics
metrics(knn_preds,
        truth = cs_position,
        estimate = .pred)

### KNN predictions for 2025 winner using past 5 years weighted data

df_2025 <- df %>%
  filter(year >= 2020, year <= 2024) %>%
  mutate(weight = case_when(
    year == 2024 ~ 5,
    year == 2023 ~ 4,
    year == 2022 ~ 3,
    year == 2021 ~ 2,
    year == 2020 ~ 1
  )) %>%
  group_by(constructor, constructorId) %>%
  summarise(
    avg_qual_position = weighted.mean(avg_qual_position, weight),
    avg_lap_time      = weighted.mean(avg_lap_time, weight),
    avg_stop_time     = weighted.mean(avg_stop_time, weight),
    avg_final_grid    = weighted.mean(avg_final_grid, weight),
    avg_final_position= weighted.mean(avg_final_position, weight),
    avg_cs_position   = weighted.mean(cs_position, weight),
    .groups = "drop"
  ) %>%
  mutate(
    raceId = -1,
    year   = 2025,
    round  = 0
  )

knn_2025_preds <- predict(final_knn, df_2025) |>
  bind_cols(df_2025) |>
  arrange(.pred)

knn_2025_preds |>
  select(constructor, predicted_rank = .pred) 


```

### Random Forest
```{r}
# recipe for random forest
rf_rec <- recipe(cs_position ~ ., data = train_data) |>
  update_role(raceId, constructorId, constructor, new_role = "ID") |>
  step_impute_median(all_numeric_predictors())


# model specification
rf_model <- rand_forest(
  mtry = tune(),
  trees = 500,
  min_n = tune()
) |>
  set_engine("randomForest") |>
  set_mode("regression")

# workflow
rf_wf <- workflow() |>
  add_recipe(rf_rec) |>
  add_model(rf_model)


# cross validation
set.seed(123)
cv_folds <- vfold_cv(train_data, v = 5, strata = cs_position)

rf_grid <- grid_regular(
  mtry(range = c(1, 3)),   # we have 3 predictors
  min_n(range = c(2, 10)),
  levels = 5
)

rf_res <- tune_grid(
  rf_wf,
  resamples = cv_folds,
  grid = rf_grid,
  metrics = metric_set(rmse, mae, rsq)
)

collect_metrics(rf_res)

# select best hyperparameters
best_rf <- select_best(rf_res, metric = "rmse")
best_rf

# fit final random forest model 
final_rf <- finalize_workflow(rf_wf, best_rf) |>
  fit(train_data)

# predict on test set
rf_preds <- predict(final_rf, test_data) |>
  bind_cols(test_data)

#Performance
metrics(rf_preds, truth = cs_position, estimate = .pred)


### Predict RF winner using past 5 years weighted
rf_2025_preds <- predict(final_rf, df_2025) %>%
  bind_cols(df_2025) %>%
  arrange(.pred)

rf_2025_preds %>%
  select(constructor, predicted_rank = .pred)

```

### Linear Regression
```{r}
# recipe for slr
lm_rec <- recipe(cs_position~., data=train_data) |>
  update_role(raceId, constructorId, constructor, new_role = "ID") |>
  step_impute_median(all_numeric_predictors()) |>
  step_normalize(all_numeric_predictors())

# model specification
lm_model <- linear_reg() |>
  set_engine("lm") |>
  set_mode("regression")

# workflow
lm_wf <- workflow() |>
  add_recipe(lm_rec) |>
  add_model(lm_model)

# resample
lm_res <- fit_resamples(
  lm_wf,
  resamples = cv_folds,
  metrics = metric_set(rmse, mae, rsq)
)

collect_metrics(lm_res)

# fit
final_lm <- fit(lm_wf, data = train_data)

# predict on test set
lm_preds <- predict(final_lm, test_data) |>
  bind_cols(test_data)

# performance
metrics(lm_preds, truth = cs_position, estimate = .pred)

# predict SLR winner using past 5 years weighted
lm_2025_preds <- predict(final_lm, df_2025) %>%
  bind_cols(df_2025) %>%
  arrange(.pred)

lm_2025_preds %>%
  select(constructor, predicted_rank = .pred)


```

### Result Visualizations
```{r}
### Ranking results 
# Convert continuous predictions to ordinal ranks
knn_2025_plot <- knn_2025_preds %>%
  mutate(predicted_rank = rank(.pred, ties.method = "first")) %>%
  select(constructor, predicted_rank)

rf_2025_plot <- rf_2025_preds %>%
  mutate(predicted_rank = rank(.pred, ties.method = "first")) %>%
  select(constructor, predicted_rank)

lm_2025_plot <- lm_2025_preds %>%
  mutate(predicted_rank = rank(.pred, ties.method = "first")) %>%
  select(constructor, predicted_rank)


# KNN
ggplot(knn_2025_plot, aes(x = reorder(constructor, -predicted_rank), y = predicted_rank)) +
  geom_col(fill = "steelblue") +  
  labs(
    title = "KNN Predicted 2025 Rankings",
    x = "Constructor",
    y = "Predicted Rank"
  ) +
  coord_flip() +  # Makes it horizontal
  theme_minimal(base_size = 14)


# Random Forest 
ggplot(rf_2025_plot, aes(x = reorder(constructor, -predicted_rank), y = predicted_rank)) +
  geom_col(fill = "firebrick") +
  labs(
    title = "RF Predicted 2025 Rankings",
    x = "Constructor",
    y = "Predicted Rank"
  ) +
  coord_flip() +
  theme_minimal(base_size = 14)

# SLR
ggplot(lm_2025_plot, aes(x = reorder(constructor, -predicted_rank), y = predicted_rank)) +
  geom_col(fill = "limegreen") +
  labs(
    title = "SLR Predicted 2025 Rankings",
    x = "Constructor",
    y = "Predicted Rank"
  ) +
  coord_flip() +
  theme_minimal(base_size = 14)


### Predicted vs Actual Championship Rank

all_preds <- bind_rows(
  knn_preds %>% mutate(model = "KNN"),
  rf_preds  %>% mutate(model = "Random Forest"),
  lm_preds %>% mutate(model = "SLR")
)

ggplot(all_preds, aes(x = cs_position, y = .pred, color = model)) +
  geom_point(alpha = 0.6) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  scale_x_reverse() +
  scale_y_reverse() +
  labs(
    x = "Actual Championship Rank",
    y = "Predicted Championship Rank",
    color = "Model"
  ) +
  theme_minimal(base_size = 14)


```




